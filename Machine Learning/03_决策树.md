### 决策树

- 时间：2018-08-16
- 摘要：主要介绍了决策树算法ID3，以及如何实现最好特征划分
- 优缺点：复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可处理不相关特征数据；但是可能会产生过度匹配，适用于__标称型数据__ 

#### 流程

```python
# ==============================================
# 输入：数据集
# 输出：构造好的决策树(也即训练集)
# ==============================================
# 创建决策树
def createTree:
     if (数据集中所有样本分类一致):
         创建携带类标签的叶子节点
     else:
         寻找划分数据集的最好特征
         根据最好特征划分数据集
         for 每个划分的数据集:
             创建决策子树(递归方式)
```

####寻找最好特征 

划分数据集的最大原则是：将无序的数据变得更加有序。

ID3算法思路：如果以某种特征来划分数据集，会导致数据集发生最大程度的改变，那么就使用这种特征值来划分。一般可以用`熵`在衡量数据集的变化程度，计算公式如下:
$$
H=-\sum_{i=1}^nP(x_i)log_2P(x_i)
$$
对数据集求熵的代码如下：

```python
def cal_entropy(dataSet):
    numEnteries = len(dataSet)
    labels = {}
    for featVec in dataSet:
        currentLabel = featVec[-1]
        if currentLabel not in labels.keys():
            labels[currentLabel] = 0
        labels[currentLabel] += 1
    entropy = 0.0
    for key in labels:
        prob = float(labels[key]/numEnteries)
        entropy -= prob*log(prob,2)
    return entropy
```

#### 划分数据集

首先遍历所有特征，得到熵值最大的特征，作为划分依据，进行划分数据集

```python
# 选择最好的数据集划分特征
def chooseBestFeature(dataSet):
    numFeatures = len(dataSet[0])-1
    baseEntropy = cal_entropy(dataSet)
    bestInfoGain = 0.0
    bestFeature = -1
    for i in range(numFeatures):
        featList = [example[i] for example in dataSet]
        uniqueVals = set(featList)
        newEntropy = 0.0
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet,i,value)
            prob = len(subDataSet)/float(len(dataSet))
            newEntropy += prob * cal_entropy(subDataSet)
        infoGain = baseEntropy - newEntropy
        if (infoGain > bestInfoGain):
            bestInfoGain = infoGain
            bestFeature = i
    return bestFeature
# 划分数据集
def splitDataSet(dataSet,axis,value):
    newDataSet = []
    for featVec in dataSet:
        if featVec[axis] == value:
            redFeatVec = featVec[:axis]
            # print(redFeatVec)
            redFeatVec.extend(featVec[axis+1:])
            newDataSet.append(redFeatVec)
    return newDataSet
```

#### 参考文献

- [《机器学习实战》](https://item.jd.com/11242112.html) 
- [决策树分类算法原理与实现](https://www.cnblogs.com/muchen/p/6141978.html) 
